# Архитектура интерпретатора командной строки Ezh
## Ezh, View и Environment
`Ezh` &mdash; название программы, а также ее самый верхнеуровневый класс. Он является точкой входа, отвечает за хранение и последовательный запуск классов следующего уровня. Соответственно, обрабатывает те исключения, которые не были обработаны используемыми им классами. Его главный публичный метод, запускающий всю программу &mdash; `main`.

`Ezh` хранит в себе два объекта: интерфейса `View` и класса `Environment`. 

Интерфейс `View` отвечает за взаимодействие приложения с пользователем, а именно за получение от него ввода (метод `getInput`) в виде потока символов и за запись выходного потока программы и потока ошибок (методы `writeOutput` и `writeError` соответственно). Потоки-интерфейсы используются, как более общие варианты, чем списки строк: они хорошо проявляют себя в ленивости по отношению к потенциально большому входу; а также позволяют использовать пользовательские классы-потоки для специфических задач в будущем.<br/> 
Наконец, `View` является интерфейсом по следующей причине: в будущем, возможно, захочется поддержать различные источники и точки выхода данных программы; например, чтение из файла / запись в него; получение данных от другой программы и отправка их ей; или же чтение пользовательского рукописного ввода с графического планшета, с помощью распознавания голоса и т. д. Для выполнения текущего задания будем использовать реализацию `ConsoleView`, манипулирующей с данными аналогично оригинальному Bash &mdash; через stdin, stdout и stderr из консоли. В будущем, чтобы поддержать запуск скриптов интерпретатором (или вывод в файлы), понадобится лишь добавить конструктор и поля в `ConsoleView`, в которых при создании объекта будут открыты соответствующие потоки чтения и записи.

Важное замечание: именно `View` отвечает за то, чтобы преобразовывать пользовательский ввод в набор последовательностей символов. Т. е. в случае консоли реализация `ConsoleView` разбивает считываемый текст по неэкранированным переносам строк (экранированность определяется кавычками, как в Bash, для этого используется простой автомат); в случае ввода голосом предполагаемая реализация преобразовывала бы звук в текст и разбивала его на последовательности по, например, специальной фразе "конец команды" и т. д. Таким образом, вся работа по получению последовательностей символов и отображению результатов программы пользователю инкапсулирована в соответствующей реализации `View`.<br/>
В заключение стоит добавить, что исключения, возникающие при манипуляциях с потоками `View`, должен обрабатывать вышестоящий `Ezh` (так как считаем их ошибками приложения в целом).

Объект класса `Environment` является же хранилищем контекста сессии, т. е. глобальных переменных и ее состояния выхода `ExitStatus` (в будущем, возможно, текущей директории). Хранение и интерфейс интуитивны: переменные хранятся в изменяемой `MutableMap`, действующей из их строковых имен в их строковые значения (после экспериментов с командной строкой Bash было выявлено, что в переменных хранятся именно строки). Доступ к таблице и модификация происходят через методы `getVariable` и `putVariable`; для прочтения сразу всей таблицы предоставлен метод `getAllVariables`; чтобы же заменить все состояние текущего `Environment`-а на состояние другого, будет полезен метод `replaceWith` (применение см. в `Executor.execute`). Исключения, связанные с логикой переменных, данные методы не вызывают (так как чтение отсутствующей ранее переменной &mdash; это пустая строка аналогично поведению Bash-а), количество глобальных переменных отдельно кроме как размером памяти никак не ограничивается.

Состояние выхода `ExitStatus` же является `enum`-ом, описывающим текущий статус сессии. На данный момент поддерживается два состояния: `RUNNING` (сессия активна) и `EXITING` (сессия завершается); в будущем, возможно, добавиться уточнение статусов завершения сессии (например, аварийное или нет). Однако даже в случае двух опций `enum` обеспечивает хорошо читаемый код. Для доступа к состоянию выхода и его установке используются геттер и сеттер. Примечание: на данный момент корректной является только установка `EXITING` состояния, после чего запрещаются какие-либо операции с `Environment`, кроме чтения `ExitStatus` &mdash; при нарушении этих условий, т. е. корректности работы с `Environment`, вызванный метод бросит соответствующее исключение.<br/>

## Lexer: lex и postprocess

Наконец, перейдем к непосредственной работе с вводом пользователя, который `Ezh` получил в виде последовательности символов от `View`. Сначала `Ezh` передает ее классу `Lexer` в метод `lex`.<br/> 
Цель данного класса в соответствии с его названием: разобраться со специальными символами (кавычки, равенство, пайпы), с логикой подстановок, с правильным разбиением на лексемы и в результате вернуть список токенов. При этом важно отметить, что `Lexer` никак не использует и не проверяет смысл написанного, этим занимается `Parser` (см. далее). Про класс `Lexer` же стоит добавить, что все его методы &mdash; статические, и сам класс, таким образом, нигде не хранится и является простой абстракцией для инкапсуляции определенных методов и логики.

Вернемся к методу `lex`. Его цель: разобраться с кавычками (двойными и одинарными), знаками равенства и пайпов, и самое главное &mdash; выделить подстановки. Глобальная идея: чтобы подстановки не могли происходить бесконечно, необходимо два этапа разбиения на лексемы; первый &mdash; совершит подстановки, второму же будет запрещено это делать. Подобная идея решает проблему, кроме того, проявляется и в оригинальном Bash, поэтому мы пошли по такому пути. Собственно говоря, чтобы сделать подстановки &mdash; необходимо правильно разобрать кавычки (так как в одних подстановки работают, а в других &mdash; нет). При разборе же кавычек одновременно удобно выделять из пользовательского ввода токены знаков равенств и пайпов: они как и подстановки зависят от контекста кавычек. Причем, важно! Эксперименты с оригинальным Bash показали, что специальные символы (равенства, пайпов и т. д.), возникшие из подстановок, специального значения далее не имеют и интерпретируются шеллом как строки (возможно, команды). Тогда разбор равенств и пайпов на первом этапе лексического разбора кроме своего удобства влечет близость к поведению Bash-а &mdash; а значит, получаем разделение обязанностей между этапами.

Еще более подробно про `lex`. Как описывалось выше, это первый этап лексического разбора. Его задача разбить строку на следующие токены, избавляясь от символов `$=|’”` в специальных значениях:
* `WORD` &mdash; описывает строку, которая в дальнейшем будет интерпретироваться как одно слово (или его часть), даже при наличии пробелов внутри (т. е., например, как один аргумент команды); последнего можно добиться, использовав пробелы внутри кавычек &mdash; такое выражение под кавычками важно интерпретировать как единое целое, аналогично поведению Bash-а (оно позволяет писать больше вариантов аргументов команд и т. д.);
* `SPACE` &mdash; токен пробельного символа (или их последовательности), именно как разграничитель слов;
* `PIPE` &mdash; токен пайпа;
* `ASSIGN` &mdash; токен знака равенства в значении присваивания (т. е. знак равенства под кавычками, например, таким не является аналогично поведению Bash-а);
* `SUBST` &mdash; имя переменной, вместо которого необходимо подставить ее значение; причем переменная находится не в окружении кавычек (это влияет на интерпретацию пробелов после подстановки, см. далее);
* `QSUBST` &mdash; аналог `SUBST`, но уже в окружении двойных кавычек (в данном случае пробелы в подстановке не будут разбивать подставленную строку по пробелам).

Токены представляются классом `Token`, каждый из них в зависимости от подтипа хранит необходимую часть строки. С помощью средств Kotlin-а их можно будет перебирать подобно enum-ам.<br/>
Автомат с его принципом работы изображен на слайде под названием *Lexer*. Основными являются следующие идеи:
* все, что находится внутри одинарных кавычек, специального значения иметь не может, при этом в итоге является одним словом или его частью;
* с двойными кавычками аналогично, однако добавляется возможность подстановок &mdash; их нужно аккуратно выделять, обрабатывая места, где заканчиваются имена переменных (они происходят по спецсимволам);
* имена переменных всегда начинают новые токены, даже там, где в итоге всего процесса лексического разбора разделения на токены не будет (пример: `text”$var”`) &mdash; причиной является главная цель первого этапа, а именно, выделить переменные для подстановки в отдельные токены;
* из-за требования в пункте выше возникают иногда непросто записываемые переходы: например, в `text“$var”` на долларе необходимо закончить идущий токен `WORD`, в случае же просто `“$var”` предыдущего токена нет, поэтому и закрывать его не надо (в схеме это отмечено как `WORD?`);
* EOF (в смысле конца пользовательского ввода, т. е. неэкранированный перенос строки в данной реализации) может вести либо к ошибке, либо к успеху первого этапа.

Некоторые детали станут понятнее в описании следующего этапа. Итого, в результате `lex`-а `Ezh` получает список лексем, в котором выделены специальные токены, требующие подстановки, а также проинтерпретированы в лексемы все символы со специальными значениями. Далее он передает этот список на второй этап лексического разбора, в метод `postprocess` `Lexer`-у.

Основными задачами `postprocess`-а являются: 
* подстановка значений переменных вместо соответствующих токенов `QSUBST` и `SUBST`;
* полное избавление от токенов `SPACE`.

Задачей первого этапа было выделение подстановок и избавление от символов в спец. значениях, тогда оставшиеся задачи непосредственно подстановки и дальнейшего разбора лексем логично относятся ко второму этапу, т. е. `postprocess`-у. Схема его действий изображена на слайде *Lexer Post Processing*. 
* Сначала он выполняет подстановку в переменные токенов `QSUBST`, заменяя их на токен `WORD` со значением строки, хранимой в переменной. Значение переменных же при подстановке `Lexer` получает у `Environment`-а с глобальным контекстом, который был передан в метод `Ezh`-ом. Замечание: данная подстановка не требует дальнейших разбиений, так как `QSUBST` означает нахождение в контексте двойных кавычек, где слово по пробелам не разбивается.
* Затем аналогичным образом выполняется замена `SUBST` на строки-значения их переменных. Однако в данном случае строки-значения проходят процесс разбиения на `WORD`-ы и `SPACE`-ы, на которые уже в реальности заменяется `SUBST`. Данное отличие вызвано тем, что при подстановке вне кавычек пробелы подставляемой строки интерпретируются как разделители разных слов в Bash.
* Наконец, необходимо грамотно избавиться от `SPACE` токенов &mdash; `Parser`-у служебные символы ни к чему, он работает на уровне команд, выражений и аргументов. Перед избавлением от пробелов необходимо проверить синтаксические ошибки, с ними связанные &mdash; в данном случае это только пробелы вокруг знаков равенств, они запрещены Bash-ом и, как следствие, и нами. Наконец, перед избавлением от `SPACE`-ов необходимо соединить слова, между которыми пробелов нет &mdash; в соответствии с нашим автоматом, они могли взяться только как части выражений внутри кавычек, которые, как говорилось выше, хотим интерпретировать как одно слово. Именно здесь и становится понятной надобность `SPACE`-ов: они позволяют наглядным образом отличать ситуацию различных слов, от еще не соединенных.<br/>
Небольшой пример: 
  ```
  wc filena“$x$y”
  
  do lex:
  WORD (wc), SPACE, WORD (filena), QSUBST(x), QSUBST(y)
  
  do postprocess-1:
  WORD (wc), SPACE, WORD (filena), WORD(m), WORD(e)
  
  do postprocess-2:
  WORD (wc), WORD (filename)
  ```
Наконец, стоит добавить, что все порожденные `Lexer`-ом исключения обрабатывает `Ezh`.

В итоге лексического анализа `Ezh` получает список лексем, причем каждая из которых &mdash; либо `ASSIGN`, либо `PIPE`, либо `WORD`. Т. е. впереди предстоит преобразование этих токенов в непосредственные операции нашего терминала в смысле именно значения данных слов и операторов. Для этого `Ezh` передает полученный список лексем `Parser`-у в метод `parse`.

## Parser: parse

Автомат, описывающий принцип работы `parse`, представлен на слайде *Parser*. Идеи следующие:
* необходимо превратить токены в операции, которые можно будет как-то выполнять &mdash; их будет описывать класс `Operation` (базовый класс, ничего в себе не хранящий);
* в данном задании мы выделяем два типа операций: присваивание (класс `Assignment`, хранящий токены левой и правой части присваивания) и команда (класс `Command`, хранящий список своих аргументов);
* после многочисленных экспериментов с Bash было выявлено, что присваивания переменных в пайпах работают неочевидным образом (скорее, не работают), а несколько операций подряд, разделенных пробелами, также работают неинтуитивно &mdash; поэтому мы решили исправить это в своей версии языка; а именно, разрешили только следующие структуры операций:
   * единственная операция без пайпов;
   * несколько операций, обязательно разделенных пайпами; т. е. `<Operation> <PIPE> <Operation> <PIPE> <Operation>` и т. д.
* в момент, когда `Parser` в `parse` определил, что идет вызов команды (это соответствует случаю, когда было считано подряд более одного `WORD` или когда после `WORD` случился `PIPE` или конец ввода), первый токен `WORD` в последовательности он принимает за имя команды, оставшиеся &mdash; за ее аргументы; после чего перед ним стоит задача превратить имя команды в ее конкретный класс, наследник класса `Command`;
* наследники класса `Command` бывают двух типов: реализованные нашим приложением команды (`ExitCommand` для exit, `PwdCommand` для pwd, `EchoCommand` для echo и так далее) и остальные, которые предполагаются внешними, им соответствует класс `ExternalCommand`; никаких дополнительных полей у всех перечисленных наследников нет, однако разделение необходимо по следующей причине: каждый наследник специфично реализует свой `execute`. Это позволит команды, реализуемые в нашем приложении, отличать от их синонимичных по названию аналогов, реализуемых во внешней среде исполнения;
* чтобы `Parser` мог определять конкретные классы-наследники по названиям команд, необходимо где-то эту информацию иметь &mdash; для этого `Parser` хранит неизменяемую `Map` (настраивается вручную в коде) из `Token`-а имени команды в функциональный интерфейс `CommandSupplier`, который ссылается на конструктор соответствующего класса; 
  * такого вида хеш-таблица позволит не хранить неиспользуемые объекты, однако по необходимости их создавать; 
  * `CommandSupplier` же был использован вместо `Supplier<Command>` для более явного названия основного метода; 
  * наконец, для имени команды используется тип `Token`, а не `WORD` для расширяемости &mdash; в таком случае, например, возможно перегрузить значение некоторого оператора другой командой;
* операциям присваивания `Assignment` соответствует последовательность токенов `WORD, ASSIGN, WORD`, как и представлено в оригинальном Bash-е.

Конечно, все ошибки при парсинге будет обрабатывать вышестоящий `Ezh`.

В результате получаем список из `Operation`, которые дальше предстоит последовательно запускать: такой смысл мы закладываем в пайп (напоминание: несколько операций в нашем языке разрешены только при разделении через пайпы). Для этого `Ezh` передает полученный список и контекст с глобальными переменными в метод `execute` класса `Executor`. Он как и `Lexer`, и `Parser` является классом, у которого нет состояния, а есть только статические методы &mdash; смысл в инкапсуляции логики.

## Executor: execute

Как говорилось выше, цель `execute` &mdash; последовательно выполнить операции из переданного списка. Для выполнения соответствующей операции у нее вызывается метод `doAssign` в случае `Assignment` и `execute` в случае `Command`. Причем после каждой команды `Executor` проверяет `ExitStatus` поддерживаемого `Environment` mdash; в случае значения `EXITING` он заканчивает исполнение последовательности операций с кодом возврата последней команды. Идеи работы `execute` следующие:
* операции исполняются в однопоточном последовательном пайпе &mdash; однако потоки ввода, вывода и ошибок должны передаваться между ними аналогично поведению Bash-а; это позволит не только реализовать последовательное перенаправление вывода в ввод следующей операции в пайпе и логгирование, но и удовлетворить интерфейсу стандартных программ GNU, что может быть полезно;
* поддерживаем одну из основных идей передачи кодов возврата от операции к операции в пайпе;
* после долгих экспериментов с Bash мы пришли к выводу, что присваивания переменных в пайпах работают неинтуитивно (и на деле вообще не работают) &mdash; в нашей же программе мы выбрали наглядную логику, а именно: каждое присваивание в пайпе влияет только на локальный контекст, передаваемый как объект класса `Environment` от операции к операции в пайпе;
  * после цепочки пайпов локальные изменения контекста не добавляются в глобальный; за счет этого мы поддержали полезную возможность изменения контекста только в рамках одного пайпа;
  * при этом иметь возможность менять глобальный контекст &mdash; необходимо, для этого присваивание должно быть написано единственной командой без пайпа;
  * таким образом, мы поддержали изменение как локального, так и глобального контекстов;

Из идей работы следуют и сигнатуры методов `doAssign` и `execute`. Замечание: использование библиотеки [jproc](https://github.com/fleipold/jproc) позволяет запускать сторонние процессы, настраивая их потоки ввода-вывода и поток ошибок на желаемые `InputStream` и `OutputStream`-ы; при этом в случае с потоком вывода данные, прогоняя через массив байт, можно превращать в `InputStream`, передаваемый далее следующей команде в пайпе.<br/> 
Алгоритм же `execute` следующий:
* создать новый объект `Environment`, как копию глобального контекста; создать потоки `in`, `out` и `err`; двигаться последовательно по операциям;
* если операция присваивания &mdash; то обновить контекст и продолжить далее;
* если команда &mdash; то исполнить ее `execute`, после чего новый `in` собрать из старого `out`, а для `out` завести новый поток; запомнить ее код ошибки, чтобы передать дальше &mdash такой подход является реализацией идеи пайпа;
* если после исполнения команды в поддерживаемом `Environment` `ExitStatus` имеет значение `EXITING`, перейти к последним пунктам; 
* последние пункты: если операция в переданной последовательности единственная, то локальный `Environment` записать в глобальный, переданный `Ezh`-ом;
* затем вернуть код ошибки последней операции, `out` и `err` потоки.

После чего, наконец, `Ezh`-у останется полученные в результате исполнения потоки передать на запись `View`. После чего при состоянии выхода `RUNNING` повторить работу по циклу, иначе закончить сессию с полученным из `Execute` кодом возврата.

## GrepCommand

Одна из встроенных команд Ezh-а &mdash; `grep`, ей соответствует класс `GrepCommand`. В отличие от других встроенных команд `grep` должен поддерживать несколько видов флагов, а также один обязательный и один опциональный аргументы. По этой причине необходимо было использовать библиотеку для разбора аргументов &mdash; мы выбрали [Clickt](https://ajalt.github.io/clikt/). Почему ее (рядом с каждой библиотекой написано ее число звезд на Github):
* [Apache Commons CLI](https://commons.apache.org/proper/commons-cli/), `0.2k` &mdash; не понравился далеко не лаконичным интерфейсом и отсутствием специфичной версии для Kotlin-а;
* [picocli](https://picocli.info/),`3.4k` &mdash; имеет более удобный интерфейс, чем `Apache`, и даже специализацию для Kotlin; однако последняя все равно использует многословный Java стиль, за счет чего проигрывает следующим претендентам;
* [kotlinx-cli](https://github.com/Kotlin/kotlinx-cli), `0.6k` &mdash; 100% Kotlin библиотека с лаконичным и говорящим интерфейсом, однако она не предоставляет возможности переопределить встроенную обработку ошибок, которая делает `exit` и пишет в `System.out` (что для наследника `Command` непозволительно);
* [kotlin-argparser](https://github.com/xenomachina/kotlin-argparser), `0.4k` &mdash; еще одна 100% Kotlin библиотека, но уже с возможностью настраивать обработку ошибок; однако со странными названиями методов и исключений;
* наконец, [Clikt](https://ajalt.github.io/clikt/), `1.8k` &mdash; 100% Kotlin библиотека, выпущенная после двух вышеупомянутых; имеет лаконичный интерфейс с говорящими названиями методов, предоставляет возможность пользовательской обработки ошибок; кроме того, имеет теоретически применимые в будущем фичи, такие как: использование переменных окружения и подсказки по вводу команды.

*Метод поиска библиотек:* просмотрели первую страницу выдачи в Google, вспомнили уже использованные в прошлых проектах технологии; качество проектов валидировали в том числе по количеству звезд на Github, тем самым рассматривая только самые популярные библиотеки (что дает надежду на качество). В принципе же `Clikt` при первой встречи и последующем ее внимательном изучении полностью удовлетворила текущим
* как техническим (поддержка Kotlin и возможность гибкой обработки ошибок),
* так и идеологическим (лаконичность и читаемость кода, популярность библиотеки, современность, полезный в будущем дополнительный функционал) потребностям. 

В контексте приведенных выше кандидатов и ограниченного времени `Clikt` стал идеальным решением.
